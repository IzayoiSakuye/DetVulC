# gnn_vuln_scanner/multilabel_graph_builder.py
import torch
import pandas as pd
import networkx as nx
import re
from torch_geometric.data import Data
from tqdm import tqdm
import pickle
import ast
import numpy as np


class MultiLabelGraphBuilder:
    """å¤šæ ‡ç­¾å›¾æ•°æ®æ„å»ºå™¨"""

    def __init__(self):
        # å®šä¹‰æ‰€æœ‰å¯èƒ½çš„æ¼æ´ç±»å‹
        self.vuln_types = [
            'buffer_overflow',
            'use_after_free',
            'double_free',
            'null_pointer',
            'integer_overflow',
            'format_string',
            'command_injection',
            'path_traversal',
            'race_condition',
            'memory_leak'
        ]

        # åˆ›å»ºæ¼æ´ç±»å‹åˆ°ç´¢å¼•çš„æ˜ å°„
        self.vuln_type_to_idx = {vuln: idx for idx, vuln in enumerate(self.vuln_types)}
        self.num_classes = len(self.vuln_types)

        # LLVM IRæ¨¡å¼
        self.instruction_patterns = {
            'call': r'call\s+(?:.*?)@(\w+)',
            'store': r'store\s+',
            'load': r'load\s+',
            'alloca': r'alloca\s+',
            'getelementptr': r'getelementptr\s+',
            'phi': r'phi\s+',
            'select': r'select\s+'
        }

        self.dangerous_functions = {
            'system', 'exec', 'execl', 'execv', 'popen', 'gets',
            'strcpy', 'strcat', 'sprintf', 'scanf', 'printf',
            'malloc', 'free', 'realloc'
        }

    def build_ast_graph(self, ir_code):
        """å°†LLVM IRä»£ç æ„å»ºä¸ºASTå›¾"""
        # åˆ›å»ºå›¾
        G = nx.DiGraph()
        node_id = 0
        lines = ir_code.strip().split('\n')

        # ç¬¬ä¸€éï¼šåˆ›å»ºèŠ‚ç‚¹
        for i, line in enumerate(lines):
            line = line.strip()
            if not line or line.startswith(';'):  # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
                continue

            # æå–èŠ‚ç‚¹ç‰¹å¾
            features = self._extract_node_features(line)
            G.add_node(node_id,
                       line=line,
                       features=features,
                       line_num=i)
            node_id += 1

        # ç¬¬äºŒéï¼šåˆ›å»ºè¾¹ï¼ˆæ§åˆ¶æµå’Œæ•°æ®æµï¼‰
        nodes = list(G.nodes())
        if len(nodes) > 1:
            for i in range(len(nodes) - 1):
                G.add_edge(nodes[i], nodes[i + 1], edge_type='control_flow')
        elif len(nodes) == 1:
            # è‡ªç¯è¾¹
            G.add_edge(nodes[0], nodes[0], edge_type='control_flow')

        return G

    def _extract_node_features(self, line):
        """æå–èŠ‚ç‚¹ç‰¹å¾"""
        features = {
            'instruction_type': 'unknown',
            'has_dangerous_call': False,
            'line_length': len(line),
            'num_operands': len(line.split(',')) if ',' in line else 1,
            'contains_ptr': '*' in line,
            'contains_array': '[' in line or ']' in line
        }

        # è¯†åˆ«æŒ‡ä»¤ç±»å‹
        for inst_type, pattern in self.instruction_patterns.items():
            if re.search(pattern, line):
                features['instruction_type'] = inst_type
                # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº†å±é™©å‡½æ•°
                if inst_type == 'call':
                    match = re.search(pattern, line)
                    if match and match.group(1) in self.dangerous_functions:
                        features['has_dangerous_call'] = True
                break

        return features

    def parse_detailed_vuln_types(self, detailed_vuln_str):
        """è§£æè¯¦ç»†çš„æ¼æ´ç±»å‹å­—ç¬¦ä¸²"""
        try:
            # å°è¯•è§£æJSONæ ¼å¼
            if isinstance(detailed_vuln_str, str):
                vuln_list = ast.literal_eval(detailed_vuln_str)
                if isinstance(vuln_list, list):
                    return vuln_list
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æŒ‰é€—å·åˆ†å‰²
            if isinstance(detailed_vuln_str, str):
                return [v.strip() for v in detailed_vuln_str.split(',') if v.strip()]

        return []

    def create_multilabel(self, detailed_vuln_types):
        """åˆ›å»ºå¤šæ ‡ç­¾å‘é‡"""
        # åˆå§‹åŒ–é›¶å‘é‡
        label_vector = [0] * self.num_classes

        # è§£ææ¼æ´ç±»å‹
        vuln_list = self.parse_detailed_vuln_types(detailed_vuln_types)

        # è®¾ç½®å¯¹åº”ä½ç½®ä¸º1
        for vuln_type in vuln_list:
            vuln_type = vuln_type.lower().strip()
            if vuln_type in self.vuln_type_to_idx:
                idx = self.vuln_type_to_idx[vuln_type]
                label_vector[idx] = 1

        return label_vector

    def graph_to_pyg_data(self, G, multilabel):
        """å°†NetworkXå›¾è½¬æ¢ä¸ºPyTorch Geometric Dataå¯¹è±¡"""
        if len(G.nodes()) == 0:
            # åˆ›å»ºä¸€ä¸ªé»˜è®¤èŠ‚ç‚¹ä»¥é˜²å›¾ä¸ºç©º
            G.add_node(0, features=self._extract_node_features(""), line="")

        # èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ
        node_features = []
        for node_id in sorted(G.nodes()):
            features = G.nodes[node_id].get('features', self._extract_node_features(""))
            # å°†ç‰¹å¾è½¬æ¢ä¸ºæ•°å€¼å‘é‡
            feature_vector = self._features_to_vector(features)
            node_features.append(feature_vector)

        x = torch.FloatTensor(node_features)

        # è¾¹ç´¢å¼•
        if len(G.edges()) > 0:
            edge_index = []
            for edge in G.edges():
                src, dst = edge
                edge_index.append([src, dst])
            edge_index = torch.LongTensor(edge_index).t().contiguous()
        else:
            # å¦‚æœæ²¡æœ‰è¾¹ï¼Œåˆ›å»ºè‡ªç¯è¾¹
            edge_index = torch.LongTensor([[0], [0]]) if len(G.nodes()) > 0 else torch.LongTensor([[], []])

        # å¤šæ ‡ç­¾
        y = torch.FloatTensor(multilabel)

        # å…¨å±€æ± åŒ–æ‰€éœ€çš„æ‰¹æ¬¡ä¿¡æ¯ï¼ˆå•å›¾ï¼‰
        batch = torch.zeros(x.size(0), dtype=torch.long)

        return Data(x=x, edge_index=edge_index, y=y, batch=batch)

    def _features_to_vector(self, features):
        """å°†ç‰¹å¾å­—å…¸è½¬æ¢ä¸ºæ•°å€¼å‘é‡"""
        # æŒ‡ä»¤ç±»å‹ç¼–ç 
        instruction_types = ['unknown', 'call', 'store', 'load', 'alloca',
                             'getelementptr', 'phi', 'select']
        inst_type_vec = [1 if features['instruction_type'] == t else 0
                         for t in instruction_types]

        # å…¶ä»–æ•°å€¼ç‰¹å¾
        other_features = [
            float(features['has_dangerous_call']),
            min(float(features['line_length']) / 1000.0, 1.0),  # å½’ä¸€åŒ–å¹¶é™åˆ¶èŒƒå›´
            min(float(features['num_operands']) / 10.0, 1.0),  # å½’ä¸€åŒ–å¹¶é™åˆ¶èŒƒå›´
            float(features['contains_ptr']),
            float(features['contains_array'])
        ]

        return inst_type_vec + other_features

    def build_from_csv(self, csv_file, output_file=None):
        """ä»CSVæ„å»ºå¤šæ ‡ç­¾å›¾æ•°æ®é›†"""
        print("ğŸ—ï¸  å¼€å§‹æ„å»ºå¤šæ ‡ç­¾å›¾æ•°æ®é›†...")

        # è¯»å–æ•°æ®
        df = pd.read_csv(csv_file)
        print(f"ğŸ“Š åŸå§‹æ•°æ®: {len(df)} æ¡è®°å½•")

        # æ¸…ç†æ•°æ®
        df = df.dropna(subset=['ir_code'])
        df = df[df['ir_code'].str.len() > 10]
        print(f"ğŸ§¹ æ¸…ç†åæ•°æ®: {len(df)} æ¡è®°å½•")

        # æ£€æŸ¥å¿…éœ€åˆ—
        required_columns = ['ir_code', 'detailed_vuln_types']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            print(f"âš ï¸  ç¼ºå°‘å¿…éœ€åˆ—: {missing_columns}")
            # åˆ›å»ºé»˜è®¤çš„detailed_vuln_typesåˆ—
            if 'detailed_vuln_types' not in df.columns:
                df['detailed_vuln_types'] = df.get('label', 0).apply(
                    lambda x: "['safe']" if x == 0 else "['buffer_overflow']"
                )

        graph_data_list = []
        failed_count = 0

        for idx, row in tqdm(df.iterrows(), total=len(df), desc="æ„å»ºå›¾"):
            try:
                # æ„å»ºASTå›¾
                G = self.build_ast_graph(row['ir_code'])

                # åˆ›å»ºå¤šæ ‡ç­¾
                multilabel = self.create_multilabel(row.get('detailed_vuln_types', "['safe']"))

                # è½¬æ¢ä¸ºPyG Dataå¯¹è±¡
                pyg_data = self.graph_to_pyg_data(G, multilabel)

                # éªŒè¯æ•°æ®
                if pyg_data.x.size(0) == 0:
                    print(f"  âš ï¸  è·³è¿‡ç©ºå›¾: æ ·æœ¬ {idx}")
                    failed_count += 1
                    continue

                # æ·»åŠ å…ƒä¿¡æ¯
                pyg_data.metadata = {
                    'index': idx,
                    'file_path': row.get('file_path', ''),
                    'primary_vuln_type': row.get('primary_vuln_type', 'safe'),
                    'detailed_vuln_types': row.get('detailed_vuln_types', "['safe']"),
                    'original_label': row.get('label', 0)  # åŸå§‹çš„äºŒåˆ†ç±»æ ‡ç­¾
                }

                graph_data_list.append(pyg_data)

            except Exception as e:
                print(f"  âš ï¸  å¤„ç†æ ·æœ¬ {idx} æ—¶å‡ºé”™: {e}")
                failed_count += 1
                continue

        print(f"âœ… å¤šæ ‡ç­¾å›¾æ•°æ®é›†æ„å»ºå®Œæˆ: {len(graph_data_list)} ä¸ªå›¾ (å¤±è´¥: {failed_count})")

        # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
        if graph_data_list:
            self.analyze_label_distribution(graph_data_list)

        # ä¿å­˜æ•°æ®é›†
        if output_file and graph_data_list:
            with open(output_file, 'wb') as f:
                pickle.dump(graph_data_list, f)
            print(f"ğŸ’¾ å›¾æ•°æ®é›†å·²ä¿å­˜åˆ°: {output_file}")

        return graph_data_list

    def analyze_label_distribution(self, graph_data_list):
        """åˆ†ææ ‡ç­¾åˆ†å¸ƒ"""
        label_counts = [0] * self.num_classes
        sample_counts = []

        for data in graph_data_list:
            labels = data.y.tolist()
            sample_counts.append(sum(labels))  # æ¯ä¸ªæ ·æœ¬çš„æ¼æ´æ•°é‡
            for j, label in enumerate(labels):
                label_counts[j] += label

        print("ğŸ“ˆ æ ‡ç­¾åˆ†å¸ƒç»Ÿè®¡:")
        for i, (vuln_type, count) in enumerate(zip(self.vuln_types, label_counts)):
            print(f"   {vuln_type}: {int(count)} ä¸ªæ ·æœ¬")

        if sample_counts:
            print(f"ğŸ“Š å¹³å‡æ¯æ ·æœ¬æ¼æ´æ•°: {sum(sample_counts) / len(sample_counts):.2f}")
            print(f"ğŸ“Š æ ·æœ¬æ¼æ´æ•°åˆ†å¸ƒ: {sorted(list(set(sample_counts)))}")


def main_build_multilabel_graphs():
    """æ„å»ºå¤šæ ‡ç­¾å›¾æ•°æ®é›†çš„ä¸»å‡½æ•°"""
    csv_file = "data/llvm_data.csv"
    output_file = "data/graph_dataset.pkl"

    try:
        builder = MultiLabelGraphBuilder()
        graph_data_list = builder.build_from_csv(csv_file, output_file)
        print(f"ğŸ‰ æˆåŠŸæ„å»º {len(graph_data_list)} ä¸ªå¤šæ ‡ç­¾å›¾!")
        return graph_data_list
    except Exception as e:
        print(f"âŒ æ„å»ºå¤šæ ‡ç­¾å›¾æ•°æ®é›†æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    main_build_multilabel_graphs()
